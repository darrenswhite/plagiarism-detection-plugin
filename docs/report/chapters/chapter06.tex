\chapter{Iteration 3}
\section{Planning}
This iteration will mainly focus on adding unit tests to the back-end Python server. These stories were initially due for the previous sprint, but were not completed. Below is the list of stories and their assigned story points. The list is displayed in completion order.

\begin{itemize}
\item Show all submissions on staff dashboard: 1 point
\item Add Python nose tests: 3 points
\end{itemize}

\section{Implementation}
Displaying students' submissions on the staff dashboard, is similar to the already existing student dashboard. The only difference is to remove the student uid filter from the database query. Each submission needed to have some form of identification, so each submission was tagged with the user data. The staff dashboard shows the full name of the student in the submissions table.

Nosetests is being used for the unit testing framework in Python 3. Nose extends unittest, which is the included in the Python standard library. Both unittest and nose are similar to JUnit. The mock library is also being used for the unit tests. \textit{Mocking} allows replacing parts of the application, to create specific testing scenarios. Function decorators are used to specify which functions will be mocked and which proxy data will be used.

The first unit tests to be developed were the authentication methods. The LDAP3 authentication system was mocked to "bypass" logging in as a user. This allows the authentication methods to operate as if the LDAP server responded. Instead, the tests will mock the code to return the required data. If mock was not used, then real credentials would have to be used, and the tests would have to be able to connect to the LDAP server on the Aberystwyth University network. The sign-in test is still incomplete, due to the database methods not being mocked. When a user signs in, their details are inserted into the database. MockupDB is a Python 3 package. It is used to create a mock server for testing the MongoDB code. The approach that MockupDB is different from mocking methods. But the documentation and an online blog was used for reference\cite{DavisMongoDB}. The server code had to be refactored to account for the mocking of the database. Both the test environment and production environment need to use the same server instances (Flask application and MongoDB client). If not, then the tests would fail. When the tests are set up, the MongoDB client is replaced with the mocked instance. The sign-in test will send a POST request to the Flask application (in a new thread). Whenever the database receives a query, the test must accept (or deny) the query, then send a response with the appropriate data. In this test case, a query is sent to retrieve the user data (the user that is attempting to sign-in). The test will acknowledge the query, and then send back None. None is sent because the user has not signed in previously. If the user had previously signed in, then the user details would be sent back instead - but that's another test case. Another request is received for inserting data into the database. This is upon successful authentication. The mocked LDAP server was used for this and simply returned True when authentication was tested. The insertion is acknowledged and the data that is to be inserted is validated. This validation will either fail or pass the test.

Once this first sign-in test was in place, the other test case scenarios would much be easier to write. Some of the other scenarios are, sign-in after previously signing in, and sign-in with incorrect credentials. Dashboard tests will be developed in a future sprint.

\section{Retrospective}
The issues with the previous sprint have continued into this iteration, unfortunately. The velocity is 4, which also follows the previous iteration. 
