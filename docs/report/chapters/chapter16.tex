\chapter{Conclusions}
\section{Introduction}
% Tie back in to the introduction and background
As stated in \autoref{chp:introduction}, the main objective of detecting plagiarism, is finding pieces of work which originated from another source. This higher level objective has been kept in mind throughout this whole project. This chapter will conclude if that objective has been met, and to what level it has been achieved.

\section{Goal}
% Was the goal achieved of tracking and identifying plagiarism in IntelliJ?
% How does this project actually compare to the other systems?
Two problems were identified in \autoref{chp:background}; tracking the work as it's being written, and identifying plagiarised work. Both of these problems have been researched, implemented, and solved.

Tracking the work has been achieved by developing an IntelliJ IDEA Plugin. This plugin tracks all file changes in the background of the IDE editor and saves these changes to an 128-bit AES encrypted XML file.

Identifying the plagiarism involved developing two components; the back-end server, and post-processor. The server provides a front-end web interface for both students and staff to sign-in to. Students may submit their tracked data and view their previous submissions. Staff are able to view all students' submissions and the resulting plagiarism outcome. The post-processor's job is to process student submissions and identify plagiarism from the tracked data. Although the algorithms used to identify plagiarism are simple, they are effective, and provide a new path for detecting plagiarism. These algorithms can be dramatically improved in the future. The plugin tracking system works perfectly, but it too has room for improvement. The future improvements for both the tracking, and detection algorithms are described in \autoref{sec:future-development}.

In comparison to the other existing systems, this project seems to be one of a kind. All existing systems previously discussed in \autoref{chp:background} do not actively track the development of work. This system achieved that goal. However, the existing systems do have complex algorithms which far surpass the expectations of the algorithms used in this system.

Overall, the main objective of finding pieces of work which originated from another source has been achieved. The complexity of detection may not be as high as initially expected, but this can be improved.

\section{Future Development}
\label{sec:future-development}
% Machine Learning similar to that of Bandara2012
% Automatic processing of large changes (similar to what was done in Results Analysis chapter)
All of the components can be improved dramatically. The plugin tracking can include more source classifications. The only sources identified during this project were, external file changes, clipboard, file renaming, and other (everything else, including keyboard typing, is classed as other). More classifications will improve the detection algorithms to be more accurate and will lead to pattern recognition. A much larger improvement would be to implement the continuous server design as described in \autoref{chp:background}. This would remove the need for students to interact with the web application, improving the overall user experience.

The back-end server has plenty of room for improvement. Adding a load balancer with multiple servers would reduce load and add redundancy preventing any problems if the server was the fail. This can be done with the added support of Docker and Docker Compose. Other container orchestration tools could also be added to improve system scalability and stability, such as Docker Swarm or Kubernetes. The visual and functional aspects of the web application can be further refined. Multiple filtering options for submissions could be added. These filtering options may include, module, name, date, and plagiarism value range. A useful automated feature would be notifications for potential plagiarised submissions. This would notify staff when a new submission has been detected to contain plagiarism or UAC.

The post-processor is the brains of the system. Implementing more intelligent plagiarism detection algorithms would vastly improve the detection of plagiarism in submissions. A great starting point would be to automate the analysis performed in \autoref{chp:results}. Being able to automatically identify large changes and detect if they cause plagiarism or not would be a big stepping stone and would remove some of the manual analysis required. More sophisticated algorithms would include machine learning. A similar approach to that of Bandara and Wijayrathna would be a good place to start\cite{Bandara2012}. Being able to learn how each students develop their code, then analysing their work for outliers would allow for direct identification of plagiarism code.

Several stories in the backlog were not completed during development. These stories were not a high priority, but may be completed in the future. These stories were:

\begin{itemize}
\item \textbf{Detect automatic code generation} - To improve the detection algorithms, the tracking classification of sources can be improved to be more specific. Detecting automatic code generation such as, \textit{insert constructor}, and \textit{generate toString} will be a major improvement.
\item \textbf{Detect code auto-complete} - As with detecting automatic code generation, detecting code auto-completion will help improve plagiarism detection.
\item \textbf{Detect code refactoring} - Class renaming has already been implemented, but there are many more forms of refactoring which can be detected and will only improve the system further.
\item \textbf{Allow resubmissions for previous submissions in student dashboard} - Allow resubmissions for students will improve the user experience of the web application. This will reduce duplicate submissions.
\item \textbf{Add a module filter to staff dashboard} - Currently the staff dashboard will display all student submissions. Being able to filter the submissions would greatly improve the user experience.
\item \textbf{Add pagination to submissions table} - Another user experience improvement. This would also reduce bandwidth usage.
\item \textbf{Improve submission post to use transactions if possible} - Using transactions are a key part of databases when being used by many users concurrently.
\item \textbf{Investigate how to gather training and testing data} - Gathering training and testing data would be the start of implementing machine learning techniques.
\item \textbf{Improve CPM calculation} - Currently the CPM calculation includes the time when the project is closed which dramatically reduces the CPM. Improving this will improve the detection methods.
\end{itemize}
